//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33961263
// Cuda compilation tools, release 12.4, V12.4.99
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_52
.address_size 64

	// .globl	MergerHelper1

.visible .entry MergerHelper1(
	.param .u64 MergerHelper1_param_0,
	.param .u64 MergerHelper1_param_1,
	.param .u64 MergerHelper1_param_2,
	.param .u64 MergerHelper1_param_3,
	.param .u64 MergerHelper1_param_4,
	.param .u64 MergerHelper1_param_5,
	.param .u64 MergerHelper1_param_6,
	.param .u64 MergerHelper1_param_7,
	.param .u32 MergerHelper1_param_8,
	.param .u32 MergerHelper1_param_9,
	.param .u32 MergerHelper1_param_10
)
{
	.reg .pred 	%p<24>;
	.reg .b32 	%r<41>;
	.reg .f64 	%fd<34>;
	.reg .b64 	%rd<75>;


	ld.param.u64 	%rd42, [MergerHelper1_param_0];
	ld.param.u64 	%rd43, [MergerHelper1_param_1];
	ld.param.u64 	%rd44, [MergerHelper1_param_2];
	ld.param.u64 	%rd45, [MergerHelper1_param_3];
	ld.param.u64 	%rd46, [MergerHelper1_param_4];
	ld.param.u64 	%rd47, [MergerHelper1_param_5];
	ld.param.u64 	%rd40, [MergerHelper1_param_6];
	ld.param.u64 	%rd41, [MergerHelper1_param_7];
	ld.param.u32 	%r18, [MergerHelper1_param_8];
	ld.param.u32 	%r20, [MergerHelper1_param_9];
	ld.param.u32 	%r19, [MergerHelper1_param_10];
	cvta.to.global.u64 	%rd1, %rd45;
	cvta.to.global.u64 	%rd2, %rd43;
	cvta.to.global.u64 	%rd3, %rd44;
	cvta.to.global.u64 	%rd4, %rd42;
	cvta.to.global.u64 	%rd5, %rd47;
	cvta.to.global.u64 	%rd6, %rd46;
	mov.u32 	%r21, %ntid.x;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %tid.x;
	mad.lo.s32 	%r1, %r22, %r21, %r23;
	setp.ge.s32 	%p1, %r1, %r20;
	@%p1 bra 	$L__BB0_16;

	mul.lo.s32 	%r2, %r1, %r18;
	setp.lt.s32 	%p2, %r18, 1;
	@%p2 bra 	$L__BB0_8;

	add.s32 	%r25, %r18, -1;
	and.b32  	%r37, %r18, 3;
	setp.lt.u32 	%p3, %r25, 3;
	mov.u32 	%r36, 0;
	@%p3 bra 	$L__BB0_5;

	sub.s32 	%r35, %r18, %r37;
	mul.wide.s32 	%rd7, %r2, 8;
	mov.u32 	%r36, 0;
	mov.u64 	%rd63, %rd4;
	mov.u64 	%rd64, %rd5;
	mov.u64 	%rd65, %rd1;
	mov.u64 	%rd66, %rd2;
	mov.u64 	%rd67, %rd6;
	mov.u64 	%rd68, %rd3;

$L__BB0_4:
	add.s64 	%rd48, %rd68, %rd7;
	ld.global.f64 	%fd2, [%rd48];
	ld.global.f64 	%fd3, [%rd63];
	setp.gt.f64 	%p4, %fd3, %fd2;
	selp.f64 	%fd4, %fd3, %fd2, %p4;
	add.s64 	%rd49, %rd67, %rd7;
	st.global.f64 	[%rd49], %fd4;
	add.s64 	%rd50, %rd65, %rd7;
	ld.global.f64 	%fd5, [%rd50];
	ld.global.f64 	%fd6, [%rd66];
	setp.gt.f64 	%p5, %fd6, %fd5;
	selp.f64 	%fd7, %fd5, %fd6, %p5;
	add.s64 	%rd51, %rd64, %rd7;
	st.global.f64 	[%rd51], %fd7;
	ld.global.f64 	%fd8, [%rd48+8];
	ld.global.f64 	%fd9, [%rd63+8];
	setp.gt.f64 	%p6, %fd9, %fd8;
	selp.f64 	%fd10, %fd9, %fd8, %p6;
	st.global.f64 	[%rd49+8], %fd10;
	ld.global.f64 	%fd11, [%rd50+8];
	ld.global.f64 	%fd12, [%rd66+8];
	setp.gt.f64 	%p7, %fd12, %fd11;
	selp.f64 	%fd13, %fd11, %fd12, %p7;
	st.global.f64 	[%rd51+8], %fd13;
	ld.global.f64 	%fd14, [%rd48+16];
	ld.global.f64 	%fd15, [%rd63+16];
	setp.gt.f64 	%p8, %fd15, %fd14;
	selp.f64 	%fd16, %fd15, %fd14, %p8;
	st.global.f64 	[%rd49+16], %fd16;
	ld.global.f64 	%fd17, [%rd50+16];
	ld.global.f64 	%fd18, [%rd66+16];
	setp.gt.f64 	%p9, %fd18, %fd17;
	selp.f64 	%fd19, %fd17, %fd18, %p9;
	st.global.f64 	[%rd51+16], %fd19;
	ld.global.f64 	%fd20, [%rd48+24];
	ld.global.f64 	%fd21, [%rd63+24];
	setp.gt.f64 	%p10, %fd21, %fd20;
	selp.f64 	%fd22, %fd21, %fd20, %p10;
	st.global.f64 	[%rd49+24], %fd22;
	ld.global.f64 	%fd23, [%rd50+24];
	ld.global.f64 	%fd24, [%rd66+24];
	setp.gt.f64 	%p11, %fd24, %fd23;
	selp.f64 	%fd25, %fd23, %fd24, %p11;
	st.global.f64 	[%rd51+24], %fd25;
	add.s32 	%r36, %r36, 4;
	add.s64 	%rd68, %rd68, 32;
	add.s64 	%rd67, %rd67, 32;
	add.s64 	%rd66, %rd66, 32;
	add.s64 	%rd65, %rd65, 32;
	add.s64 	%rd64, %rd64, 32;
	add.s64 	%rd63, %rd63, 32;
	add.s32 	%r35, %r35, -4;
	setp.ne.s32 	%p12, %r35, 0;
	@%p12 bra 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p13, %r37, 0;
	@%p13 bra 	$L__BB0_8;

	add.s32 	%r27, %r36, %r2;
	mul.wide.s32 	%rd52, %r27, 8;
	add.s64 	%rd74, %rd5, %rd52;
	add.s64 	%rd73, %rd1, %rd52;
	add.s64 	%rd72, %rd6, %rd52;
	add.s64 	%rd71, %rd3, %rd52;
	mul.wide.s32 	%rd53, %r36, 8;
	add.s64 	%rd70, %rd2, %rd53;
	add.s64 	%rd69, %rd4, %rd53;

$L__BB0_7:
	.pragma "nounroll";
	ld.global.f64 	%fd26, [%rd71];
	ld.global.f64 	%fd27, [%rd69];
	setp.gt.f64 	%p14, %fd27, %fd26;
	selp.f64 	%fd28, %fd27, %fd26, %p14;
	st.global.f64 	[%rd72], %fd28;
	ld.global.f64 	%fd29, [%rd73];
	ld.global.f64 	%fd30, [%rd70];
	setp.gt.f64 	%p15, %fd30, %fd29;
	selp.f64 	%fd31, %fd29, %fd30, %p15;
	st.global.f64 	[%rd74], %fd31;
	add.s64 	%rd74, %rd74, 8;
	add.s64 	%rd73, %rd73, 8;
	add.s64 	%rd72, %rd72, 8;
	add.s64 	%rd71, %rd71, 8;
	add.s64 	%rd70, %rd70, 8;
	add.s64 	%rd69, %rd69, 8;
	add.s32 	%r37, %r37, -1;
	setp.ne.s32 	%p16, %r37, 0;
	@%p16 bra 	$L__BB0_7;

$L__BB0_8:
	setp.lt.s32 	%p18, %r19, 1;
	or.pred  	%p19, %p18, %p2;
	selp.u32 	%r40, 1, 0, %p18;
	@%p19 bra 	$L__BB0_15;

	cvta.to.global.u64 	%rd38, %rd40;
	mov.u32 	%r28, 0;
	mov.u32 	%r38, %r28;

$L__BB0_10:
	mov.u32 	%r39, %r28;

$L__BB0_11:
	add.s32 	%r30, %r39, %r38;
	mul.wide.s32 	%rd54, %r30, 8;
	add.s64 	%rd55, %rd38, %rd54;
	add.s32 	%r31, %r39, %r2;
	cvt.s64.s32 	%rd39, %r31;
	mul.wide.s32 	%rd56, %r31, 8;
	add.s64 	%rd57, %rd6, %rd56;
	ld.global.f64 	%fd32, [%rd57];
	ld.global.f64 	%fd1, [%rd55];
	setp.gtu.f64 	%p20, %fd1, %fd32;
	@%p20 bra 	$L__BB0_14;

	shl.b64 	%rd58, %rd39, 3;
	add.s64 	%rd59, %rd5, %rd58;
	ld.global.f64 	%fd33, [%rd59];
	setp.ltu.f64 	%p21, %fd1, %fd33;
	add.s32 	%r39, %r39, 1;
	@%p21 bra 	$L__BB0_14;

	setp.lt.s32 	%p22, %r39, %r18;
	mov.u32 	%r40, 0;
	@%p22 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_15;

$L__BB0_14:
	add.s32 	%r38, %r38, %r18;
	setp.lt.s32 	%p23, %r38, %r19;
	mov.u32 	%r40, 1;
	@%p23 bra 	$L__BB0_10;

$L__BB0_15:
	cvta.to.global.u64 	%rd60, %rd41;
	mul.wide.s32 	%rd61, %r1, 4;
	add.s64 	%rd62, %rd60, %rd61;
	st.global.u32 	[%rd62], %r40;

$L__BB0_16:
	ret;

}
	// .globl	_Z17matrixMulMultiplePfS_S_iii
.visible .entry _Z17matrixMulMultiplePfS_S_iii(
	.param .u64 _Z17matrixMulMultiplePfS_S_iii_param_0,
	.param .u64 _Z17matrixMulMultiplePfS_S_iii_param_1,
	.param .u64 _Z17matrixMulMultiplePfS_S_iii_param_2,
	.param .u32 _Z17matrixMulMultiplePfS_S_iii_param_3,
	.param .u32 _Z17matrixMulMultiplePfS_S_iii_param_4,
	.param .u32 _Z17matrixMulMultiplePfS_S_iii_param_5
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<16>;
	.reg .b32 	%r<38>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd5, [_Z17matrixMulMultiplePfS_S_iii_param_0];
	ld.param.u64 	%rd6, [_Z17matrixMulMultiplePfS_S_iii_param_1];
	ld.param.u64 	%rd7, [_Z17matrixMulMultiplePfS_S_iii_param_2];
	ld.param.u32 	%r18, [_Z17matrixMulMultiplePfS_S_iii_param_3];
	ld.param.u32 	%r19, [_Z17matrixMulMultiplePfS_S_iii_param_4];
	ld.param.u32 	%r20, [_Z17matrixMulMultiplePfS_S_iii_param_5];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd6;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %ctaid.y;
	mov.u32 	%r23, %tid.y;
	mad.lo.s32 	%r1, %r22, %r21, %r23;
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	mov.u32 	%r26, %tid.x;
	mad.lo.s32 	%r2, %r25, %r24, %r26;
	setp.ge.s32 	%p1, %r1, %r19;
	setp.ge.s32 	%p2, %r2, %r18;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB1_8;

	mad.lo.s32 	%r33, %r1, %r18, %r2;
	setp.lt.s32 	%p4, %r20, 1;
	@%p4 bra 	$L__BB1_8;

	cvta.to.global.u64 	%rd8, %rd5;
	mul.wide.s32 	%rd9, %r33, 4;
	add.s64 	%rd3, %rd8, %rd9;
	and.b32  	%r37, %r20, 3;
	add.s32 	%r28, %r20, -1;
	setp.lt.u32 	%p5, %r28, 3;
	mov.u32 	%r35, 0;
	@%p5 bra 	$L__BB1_5;

	mul.lo.s32 	%r30, %r19, %r18;
	shl.b32 	%r5, %r30, 2;
	sub.s32 	%r6, %r37, %r20;
	mul.wide.s32 	%rd4, %r30, 4;
	mov.u32 	%r35, 0;

$L__BB1_4:
	mul.wide.s32 	%rd10, %r33, 4;
	add.s64 	%rd11, %rd2, %rd10;
	ld.global.f32 	%f1, [%rd11];
	ld.global.f32 	%f2, [%rd3];
	mul.f32 	%f3, %f2, %f1;
	add.s64 	%rd12, %rd1, %rd10;
	st.global.f32 	[%rd12], %f3;
	add.s64 	%rd13, %rd11, %rd4;
	ld.global.f32 	%f4, [%rd13];
	ld.global.f32 	%f5, [%rd3];
	mul.f32 	%f6, %f5, %f4;
	add.s64 	%rd14, %rd12, %rd4;
	st.global.f32 	[%rd14], %f6;
	add.s64 	%rd15, %rd13, %rd4;
	ld.global.f32 	%f7, [%rd15];
	ld.global.f32 	%f8, [%rd3];
	mul.f32 	%f9, %f8, %f7;
	add.s64 	%rd16, %rd14, %rd4;
	st.global.f32 	[%rd16], %f9;
	add.s64 	%rd17, %rd15, %rd4;
	ld.global.f32 	%f10, [%rd17];
	ld.global.f32 	%f11, [%rd3];
	mul.f32 	%f12, %f11, %f10;
	add.s64 	%rd18, %rd16, %rd4;
	st.global.f32 	[%rd18], %f12;
	add.s32 	%r33, %r33, %r5;
	add.s32 	%r35, %r35, 4;
	add.s32 	%r31, %r6, %r35;
	setp.ne.s32 	%p6, %r31, 0;
	@%p6 bra 	$L__BB1_4;

$L__BB1_5:
	setp.eq.s32 	%p7, %r37, 0;
	@%p7 bra 	$L__BB1_8;

	mad.lo.s32 	%r32, %r35, %r19, %r1;
	mad.lo.s32 	%r36, %r18, %r32, %r2;
	mul.lo.s32 	%r13, %r19, %r18;

$L__BB1_7:
	.pragma "nounroll";
	mul.wide.s32 	%rd19, %r36, 4;
	add.s64 	%rd20, %rd2, %rd19;
	ld.global.f32 	%f13, [%rd20];
	ld.global.f32 	%f14, [%rd3];
	mul.f32 	%f15, %f14, %f13;
	add.s64 	%rd21, %rd1, %rd19;
	st.global.f32 	[%rd21], %f15;
	add.s32 	%r36, %r36, %r13;
	add.s32 	%r37, %r37, -1;
	setp.ne.s32 	%p8, %r37, 0;
	@%p8 bra 	$L__BB1_7;

$L__BB1_8:
	ret;

}

